{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb506449",
   "metadata": {},
   "source": [
    "# Document Model JSON Files Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d5390",
   "metadata": {},
   "source": [
    "- First of all we need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dbeca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fc6e2",
   "metadata": {},
   "source": [
    "- We will read the stores datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f21459",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df_50k = pd.read_csv('./datasets/stores_50k.csv')\n",
    "stores_df_100k = pd.read_csv('./datasets/stores_100k.csv')\n",
    "stores_df = pd.read_csv('./datasets/stores_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9856b",
   "metadata": {},
   "source": [
    "- We will create a file containing a JSON array that will be used by `mongoimport` to insert the stores into the `Stores` collection in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23160da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stores_json_array(df, dataset_size):\n",
    "    with open(f'./json_data/{dataset_size}/stores.json', 'w', encoding='utf-8') as stores_file:\n",
    "        stores_file.write('[\\n')\n",
    "        for idx, store in df.iterrows():\n",
    "            stores_file.write(f'''  {{\\n    \"id\": {store['id']},\\n    \"name\": \"{store['name']}\",\\n    \"description\": \"{store['description']}\",\\n    \"address\": \"{store['address']}\",\\n    \"city\": \"{store['city']}\",\\n    \"state\": \"{store['state']}\",\\n    \"postal_code\": \"{store['postal_code']}\",\\n    \"location\": {{\\n      \"type\": \"Point\",\\n      \"coordinates\": [{store['longitude']}, {store['latitude']}]\\n    }}\\n  }}{',' if idx != (len(df) - 1) else ''}\\n''')\n",
    "        stores_file.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b938f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stores_json_array(stores_df_50k, dataset_size='50k')\n",
    "create_stores_json_array(stores_df_100k, dataset_size='100k')\n",
    "create_stores_json_array(stores_df, dataset_size='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf4516",
   "metadata": {},
   "source": [
    "- We will read the products datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d96ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df_50k = pd.read_csv('./datasets/products_50k.csv')\n",
    "products_df_100k = pd.read_csv('./datasets/products_100k.csv')\n",
    "products_df = pd.read_csv('./datasets/products_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299ffe3",
   "metadata": {},
   "source": [
    "- We will create 4 equal sized files, each containing a JSON array that will be used by `mongoimport` to insert the products into the `Products` collection in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5966579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_products_json_arrays(df, dataset_size, num_files=4):\n",
    "    chunk_size = len(df) // num_files\n",
    "    for i in range(num_files):\n",
    "        start = i * chunk_size\n",
    "        end = (i + 1) * chunk_size if i < num_files - 1 else len(df)\n",
    "        chunk = df.iloc[start:end]\n",
    "        with open(f'./json_data/{dataset_size}/products_{i+1}.json', 'w', encoding='utf-8') as products_file:\n",
    "            products_file.write('[\\n')\n",
    "            for idx, product in chunk.iterrows():\n",
    "                products_file.write(f'''  {{\\n    \"id\": {product['id']},\\n    \"name\": \"{product['name']}\",\\n    \"description\": \"{product['description']}\",\\n    \"price\": {product['price']},\\n    \"calories\": {product['calories']},\\n    \"protein\": {product['protein']},\\n    \"carbs\": {product['carbs']},\\n    \"fat\": {product['fat']},\\n    \"store_id\": {product['store_id']}\\n  }}{',' if idx != (end - 1) else ''}\\n''')\n",
    "            products_file.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b80509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_products_json_arrays(products_df_50k, dataset_size='50k')\n",
    "create_products_json_arrays(products_df_100k, dataset_size='100k')\n",
    "create_products_json_arrays(products_df, dataset_size='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefc662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
